{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import librosa\n",
    "# import model as spkModel\n",
    "import os\n",
    "from visualization.viewer import PlotDiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def arrangeResult(labels, time_spec_rate): # {'1': [{'start':10, 'stop':20}, {'start':30, 'stop':40}], '2': [{'start':90, 'stop':100}]}\n",
    "    lastLabel = labels[0]\n",
    "    speakerSlice = {}\n",
    "    j = 0\n",
    "    for i,label in enumerate(labels):\n",
    "        if(label==lastLabel):\n",
    "            continue\n",
    "        speakerSlice = append2dict(speakerSlice, {lastLabel: (time_spec_rate*j,time_spec_rate*i)})\n",
    "        j = i\n",
    "        lastLabel = label\n",
    "    speakerSlice = append2dict(speakerSlice, {lastLabel: (time_spec_rate*j,time_spec_rate*(len(labels)))})\n",
    "    return speakerSlice\n",
    "\n",
    "def genMap(intervals):  # interval slices to maptable\n",
    "    slicelen = [sliced[1]-sliced[0] for sliced in intervals.tolist()]\n",
    "    mapTable = {}  # vad erased time to origin time, only split points\n",
    "    idx = 0\n",
    "    for i, sliced in enumerate(intervals.tolist()):\n",
    "        mapTable[idx] = sliced[0]\n",
    "        idx += slicelen[i]\n",
    "    mapTable[sum(slicelen)] = intervals[-1,-1]\n",
    "\n",
    "    keys = [k for k,_ in mapTable.items()]\n",
    "    keys.sort()\n",
    "    return mapTable, keys\n",
    "\n",
    "def fmtTime(timeInMillisecond):\n",
    "    millisecond = timeInMillisecond%1000\n",
    "    minute = timeInMillisecond//1000//60\n",
    "    second = (timeInMillisecond-minute*60*1000)//1000\n",
    "    time = '{}:{:02d}.{}'.format(minute, second, millisecond)\n",
    "    return time\n",
    "\n",
    "def load_wav(vid_path, sr):\n",
    "    wav, _ = librosa.load(vid_path, sr=sr)\n",
    "    intervals = librosa.effects.split(wav, top_db=20)\n",
    "    wav_output = []\n",
    "    for sliced in intervals:\n",
    "      wav_output.extend(wav[sliced[0]:sliced[1]])\n",
    "    return np.array(wav_output), (intervals/sr*1000).astype(int)\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=1024):\n",
    "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "# 0s        1s        2s                  4s                  6s\n",
    "# |-------------------|-------------------|-------------------|\n",
    "# |-------------------|\n",
    "#           |-------------------|\n",
    "#                     |-------------------|\n",
    "#                               |-------------------|\n",
    "def load_data(path, win_length=400, sr=16000, hop_length=160, n_fft=512, embedding_per_second=0.5, overlap_rate=0.5):\n",
    "    wav, intervals = load_wav(path, sr=sr)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    spec_mag = mag_T\n",
    "\n",
    "    spec_len = sr/hop_length/embedding_per_second\n",
    "    spec_hop_len = spec_len*(1-overlap_rate)\n",
    "\n",
    "    cur_slide = 0.0\n",
    "    utterances_spec = []\n",
    "\n",
    "    while(True):  # slide window.\n",
    "        if(cur_slide + spec_len > time):\n",
    "            break\n",
    "        spec_mag = mag_T[:, int(cur_slide+0.5) : int(cur_slide+spec_len+0.5)]\n",
    "        \n",
    "        # preprocessing, subtract mean, divided by time-wise var\n",
    "        mu = np.mean(spec_mag, 0, keepdims=True)\n",
    "        std = np.std(spec_mag, 0, keepdims=True)\n",
    "        spec_mag = (spec_mag - mu) / (std + 1e-5)\n",
    "        utterances_spec.append(spec_mag)\n",
    "\n",
    "        cur_slide += spec_hop_len\n",
    "\n",
    "    return utterances_spec, intervals\n",
    "\n",
    "def main(wav_path, embedding_per_second=1.0, overlap_rate=0.5):\n",
    "\n",
    "    # gpu configuration\n",
    "    toolkits.initialize_GPU(args)\n",
    "\n",
    "    params = {'dim': (257, None, 1),\n",
    "              'nfft': 512,\n",
    "              'spec_len': 250,\n",
    "              'win_length': 400,\n",
    "              'hop_length': 160,\n",
    "              'n_classes': 5994,\n",
    "              'sampling_rate': 16000,\n",
    "              'normalize': True,\n",
    "              }\n",
    "\n",
    "    network_eval = spkModel.vggvox_resnet2d_icassp(input_dim=params['dim'],\n",
    "                                                num_class=params['n_classes'],\n",
    "                                                mode='eval', args=args)\n",
    "    network_eval.load_weights(args.resume, by_name=True)\n",
    "\n",
    "\n",
    "    model_args, _, inference_args = uisrnn.parse_arguments()\n",
    "    model_args.observation_dim = 512\n",
    "    uisrnnModel = uisrnn.UISRNN(model_args)\n",
    "    uisrnnModel.load(SAVED_MODEL_NAME)\n",
    "\n",
    "    specs, intervals = load_data(wav_path, embedding_per_second=embedding_per_second, overlap_rate=overlap_rate)\n",
    "    mapTable, keys = genMap(intervals)\n",
    "\n",
    "    feats = []\n",
    "    for spec in specs:\n",
    "        spec = np.expand_dims(np.expand_dims(spec, 0), -1)\n",
    "        v = network_eval.predict(spec)\n",
    "        feats += [v]\n",
    "\n",
    "    feats = np.array(feats)[:,0,:].astype(float)  # [splits, embedding dim]\n",
    "    predicted_label = uisrnnModel.predict(feats, inference_args)\n",
    "\n",
    "    time_spec_rate = 1000*(1.0/embedding_per_second)*(1.0-overlap_rate) # speaker embedding every ?ms\n",
    "    center_duration = int(1000*(1.0/embedding_per_second)//2)\n",
    "    speakerSlice = arrangeResult(predicted_label, time_spec_rate)\n",
    "\n",
    "    for spk,timeDicts in speakerSlice.items():    # time map to orgin wav(contains mute)\n",
    "        for tid,timeDict in enumerate(timeDicts):\n",
    "            s = 0\n",
    "            e = 0\n",
    "            for i,key in enumerate(keys):\n",
    "                if(s!=0 and e!=0):\n",
    "                    break\n",
    "                if(s==0 and key>timeDict['start']):\n",
    "                    offset = timeDict['start'] - keys[i-1]\n",
    "                    s = mapTable[keys[i-1]] + offset\n",
    "                if(e==0 and key>timeDict['stop']):\n",
    "                    offset = timeDict['stop'] - keys[i-1]\n",
    "                    e = mapTable[keys[i-1]] + offset\n",
    "\n",
    "            speakerSlice[spk][tid]['start'] = s\n",
    "            speakerSlice[spk][tid]['stop'] = e\n",
    "\n",
    "    for spk,timeDicts in speakerSlice.items():\n",
    "        print('========= ' + str(spk) + ' =========')\n",
    "        for timeDict in timeDicts:\n",
    "            s = timeDict['start']\n",
    "            e = timeDict['stop']\n",
    "            s = fmtTime(s)  # change point moves to the center of the slice\n",
    "            e = fmtTime(e)\n",
    "            print(s+' ==> '+e)\n",
    "\n",
    "    p = PlotDiar(map=speakerSlice, wav=wav_path, gui=True, size=(25, 6))\n",
    "    p.draw()\n",
    "    p.plot.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(r'wavs/rmdmy.wav', embedding_per_second=1.2, overlap_rate=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
